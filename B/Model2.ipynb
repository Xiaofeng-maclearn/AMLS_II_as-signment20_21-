{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras as kr\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               text_code      sent  \\\n",
      "0      [    3     1     0     2  5717    31   108 108...  negative   \n",
      "1      [    3     0   332     0    38     2   934   2...  negative   \n",
      "2      [   1    0    2    7  315    0    0 1144    0 ...  negative   \n",
      "3      [    1     0     0  1373  4294   253    41    ...  negative   \n",
      "4      [    0     1    10    17   712     0  2404    ...  negative   \n",
      "...                                                  ...       ...   \n",
      "10546  [  11    0    0    0  534    0    0  263    0 ...  positive   \n",
      "10547  [  12    1  550    0   22   46 6911  121   14 ...  positive   \n",
      "10548  [   0   61    0   92  121   14    0  133 6174 ...  positive   \n",
      "10549  [    0     9    10   335     0     0   183   2...  positive   \n",
      "10550  [   0    1    0  638    0    0  177  247    9 ...  positive   \n",
      "\n",
      "             topic  \n",
      "0      amy schumer  \n",
      "1      amy schumer  \n",
      "2      amy schumer  \n",
      "3      amy schumer  \n",
      "4      amy schumer  \n",
      "...            ...  \n",
      "10546         zayn  \n",
      "10547         zayn  \n",
      "10548         zayn  \n",
      "10549         zayn  \n",
      "10550         zayn  \n",
      "\n",
      "[10551 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# open and read the id-list\n",
    "df = pd.read_csv('code.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type-change function\n",
    "def textcode_to_array(textcode):\n",
    "    listOfTokens = re.split(r'\\W+',textcode)\n",
    "    # decrease the length of array since there are spaces at the start and end of the splitted list\n",
    "    codes = np.zeros(len(listOfTokens)-2, dtype=np.int) \n",
    "    for i in range(len(codes)):\n",
    "        codes[i] = int(listOfTokens[i+1])\n",
    "    return codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               text_code      sent  \\\n",
      "0      [    3     1     0     2  5717    31   108 108...  negative   \n",
      "1      [    3     0   332     0    38     2   934   2...  negative   \n",
      "2      [   1    0    2    7  315    0    0 1144    0 ...  negative   \n",
      "3      [    1     0     0  1373  4294   253    41    ...  negative   \n",
      "4      [    0     1    10    17   712     0  2404    ...  negative   \n",
      "...                                                  ...       ...   \n",
      "10546  [  11    0    0    0  534    0    0  263    0 ...  positive   \n",
      "10547  [  12    1  550    0   22   46 6911  121   14 ...  positive   \n",
      "10548  [   0   61    0   92  121   14    0  133 6174 ...  positive   \n",
      "10549  [    0     9    10   335     0     0   183   2...  positive   \n",
      "10550  [   0    1    0  638    0    0  177  247    9 ...  positive   \n",
      "\n",
      "             topic                                               code  \n",
      "0      amy schumer  [3, 1, 0, 2, 5717, 31, 108, 10841, 1585, 10840...  \n",
      "1      amy schumer  [3, 0, 332, 0, 38, 2, 934, 280, 10838, 0, 0, 1...  \n",
      "2      amy schumer  [1, 0, 2, 7, 315, 0, 0, 1144, 0, 242, 125, 330...  \n",
      "3      amy schumer  [1, 0, 0, 1373, 4294, 253, 41, 0, 2, 363, 798,...  \n",
      "4      amy schumer  [0, 1, 10, 17, 712, 0, 2404, 0, 16, 14, 583, 1...  \n",
      "...            ...                                                ...  \n",
      "10546         zayn  [11, 0, 0, 0, 534, 0, 0, 263, 0, 1, 0, 6910, 0...  \n",
      "10547         zayn  [12, 1, 550, 0, 22, 46, 6911, 121, 14, 448, 0,...  \n",
      "10548         zayn  [0, 61, 0, 92, 121, 14, 0, 133, 6174, 0, 10, 0...  \n",
      "10549         zayn  [0, 9, 10, 335, 0, 0, 183, 284, 16, 0, 13464, ...  \n",
      "10550         zayn  [0, 1, 0, 638, 0, 0, 177, 247, 9, 22, 0, 0, 0,...  \n",
      "\n",
      "[10551 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# do the type change\n",
    "df['code'] = \"\"\n",
    "for i in range(df.shape[0]):\n",
    "    df.iloc[i,3] =  textcode_to_array(df.iloc[i,0])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder() \n",
    "df['topicnum'] = le.fit_transform(df.iloc[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['sent','code','topicnum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM(x,weights,bias):\n",
    "    embedding_inputs = tf.nn.embedding_lookup(embedding, x) # replace the integers in id list into embedding vectors\n",
    "    lstm_cell=tf.contrib.rnn.BasicLSTMCell(num_units) # generate a LSTM model with num_units cells in each layer\n",
    "    \n",
    "    outputs, states = tf.nn.dynamic_rnn(lstm_cell,embedding_inputs, dtype=tf.float32) # run the model and get the last output\n",
    "    outputs = tf.nn.dropout(outputs, keep_prob)     # dropout process\n",
    "    result = tf.nn.softmax(tf.matmul(outputs[:,-1,:],weights)+bias,1)  # calculate the probability vector\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\envs\\lab\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n",
      "WARNING:tensorflow:From <ipython-input-8-d0375495cdec>:26: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Attempted to use a closed Session.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d0375495cdec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mTrainData_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mTrainData_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0mTrainData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m66\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mtrainaccuracylist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTrainData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Prediction does not need dropout, so 1 is set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m     \u001b[0mValData\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m66\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mvalaccuracylist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mValData\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\lab\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1061\u001b[0m     \u001b[1;31m# Check session.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1062\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1063\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Attempted to use a closed Session.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1064\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1065\u001b[0m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Attempted to use a closed Session."
     ]
    }
   ],
   "source": [
    "trainaccuracylist = np.zeros(100)\n",
    "valaccuracylist = np.zeros(100)\n",
    "testaccuracylist = np.zeros(100)\n",
    "num_classes = 2 # positive, negative\n",
    "for i in range(100):\n",
    "    df2 = df.loc[df['topicnum']==i]\n",
    "    # use labelencoder to change the type of classes from String to integer\n",
    "    labels = le.fit_transform(df2.iloc[:,0])\n",
    "    # and then, change the type from integer to one-hot code\n",
    "    labels = kr.utils.to_categorical(labels, num_classes) \n",
    "    X_trainval,X_test,y_trainval,y_test=train_test_split(df2.iloc[:,1],labels,test_size=0.2,random_state=1) \n",
    "    X_train,X_val,y_train,y_val=train_test_split(X_trainval,y_trainval,test_size=0.25,random_state=1) \n",
    "    num_units = 16\n",
    "    batch_size=30\n",
    "    n_batch = int(len(X_train.shape)/batch_size)\n",
    "    train_rate = 0.0001\n",
    "    embedding_size = 16\n",
    "    vocabulary_size = 13465\n",
    "    x=tf.placeholder(tf.int32,shape=[None,66]) #\n",
    "    y=tf.placeholder(tf.float32,[None,num_classes])\n",
    "    weights=tf.Variable(tf.truncated_normal([num_units,num_classes],stddev=0.1))\n",
    "    bias=tf.Variable(tf.constant(0.1,shape=[num_classes]))\n",
    "    embedding = tf.get_variable('embedding', [vocabulary_size, embedding_size])\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    prediction=LSTM(x,weights,bias) # get the probability vector\n",
    "    cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))  # calculate the cost\n",
    "    train_step=tf.train.AdamOptimizer(train_rate).minimize(cost) # use optimizer to improve the model in a given rate\n",
    "    correct_predict=tf.equal(tf.argmax(y,1),tf.argmax(prediction,1)) # generate accuracy vector\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_predict,tf.float32)) # calculate accuracy\n",
    "\n",
    "    init=tf.global_variables_initializer() # initialize all variables\n",
    "\n",
    "    # run the training function\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        for j in range(n_batch):\n",
    "            TrainData_label=y_train[j*batch_size:(j+1)*n_batch]\n",
    "            TrainData_batch = kr.preprocessing.sequence.pad_sequences(X_train.iloc[j*batch_size:(j+1)*n_batch], 66) # increase the sequence length to maxlen\n",
    "            sess.run(train_step,feed_dict={x:TrainData_batch,y:TrainData_label, keep_prob: 0.75})\n",
    "    TrainData = kr.preprocessing.sequence.pad_sequences(X_train, 66)\n",
    "    trainaccuracylist[i]=sess.run(accuracy, feed_dict={x: TrainData, y: y_train, keep_prob: 1}) # Prediction does not need dropout, so 1 is set\n",
    "    ValData = kr.preprocessing.sequence.pad_sequences(X_val, 66)\n",
    "    valaccuracylist[i] = sess.run(accuracy, feed_dict={x: ValData, y: y_val, keep_prob: 1})\n",
    "    TestData = kr.preprocessing.sequence.pad_sequences(X_test, 66)\n",
    "    testaccuracylist[i] = sess.run(accuracy, feed_dict={x: TestData, y: y_test, keep_prob: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
